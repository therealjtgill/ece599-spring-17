# Trained on PTB first, then Shakespeare.
# Inserted fully connected FF layer between input nodes and LSTM cell.
# Output from PTB training looks coherent, but there's no noticeable 
# difference when the Shakespeare training starts.
(see train1.out)
6.18366e+06,1.03445e+06
38.64,21.6373
39.5379,23.6767
34.6961,20.6678
34.127,19.8683
35.061,16.2569
32.9645,6.6714
29.281,4.68477
29.8855,4.04867
38.3225,3.90714
33.2755,3.53062
52.871,3.75777
42.7856,3.59937
41.595,3.47676
50.9944,3.55005
48.6591,3.40517
50.542,3.35988
60.2992,3.10015
69.7281,3.2977
64.6284,3.18254
54.3457,3.07115
54.596,3.02593
60.2714,3.02783
67.4889,3.0472
54.1261,3.0918
78.4573,3.03749
68.803,3.0696
76.377,3.07738
70.8942,2.92704
59.7375,2.93083
53.6682,2.87256
67.1876,2.99704
88.7943,2.98986
66.143,2.98688
71.5731,3.09317
63.9253,3.11906
76.537,3.06285
69.9524,3.01611
70.8245,2.97622
83.4948,2.95679
69.0574,2.98285
62.4061,2.96426
73.1654,3.10095
52.5,3.08809
80.5456,2.82844
83.4181,3.00547
61.4138,2.97666
81.0036,2.92715
63.835,2.92921
59.0067,3.00458
66.8141,3.11501
78.1307,2.98631
85.5578,3.05306
67.4547,2.96364
64.6697,2.95211
63.3515,3.01018
54.9444,2.95396
81.429,2.95499
81.0912,3.01305
57.3025,3.16024
63.7409,3.01437
64.1601,3.06704
75.3889,2.96651
68.5982,2.99475
66.5362,3.07877
59.8339,3.05553
60.7183,3.01564
