# Trained on Shakespeare first, then PTB.
# Inserted fully connected FF layer between input nodes and LSTM cell.
# Output from Shakespeare training looks coherent, but there's no noticeable 
# difference when the PTB training starts.
(see train2.out)
22.8505,23.2238
21.2293,24.0163
21.3301,24.0753
21.3421,23.3245
22.1353,25.6126
21.3522,25.4826
20.4769,23.7873
17.6473,24.4584
12.0526,17.4932
9.31881,17.4752
7.62567,15.1512
6.88445,16.0665
6.70597,15.0732
6.31761,16.9724
6.11581,15.2091
6.06829,18.0475
6.0744,15.477
5.70819,14.6967
5.65979,20.293
5.32683,17.8625
5.56246,15.1749
5.48332,16.5688
5.40111,16.1604
5.67792,15.4001
5.21728,15.2431
5.41591,16.0335
5.26697,16.3786
5.26882,16.7211
5.23756,14.2573
5.4079,16.1418
5.60058,13.9301
5.42967,14.3322
5.23074,15.3842
5.51498,15.4907
5.46227,17.8016
5.38761,15.5036
5.07235,17.0863
5.3207,16.0242
5.38397,18.6711
5.02223,17.9008
5.64901,14.6415
5.29807,16.5042
5.6171,16.9014
5.43344,15.4425
5.57654,16.3558
5.73979,15.0379
5.2843,17.2448
5.44606,14.7111
5.40989,14.6347
5.57377,15.0531
5.56634,14.1219
5.69023,15.5534
5.12616,16.9378
5.40207,15.1455
5.32996,16.437
5.65629,16.4166
5.4605,16.0914
5.66371,16.554
5.095,14.6122
5.23023,13.8752
5.20538,15.6208
5.37063,14.624
5.49536,14.7379
5.48635,14.7932
5.36503,16.6678
5.47558,16.6238
5.47398,15.9377
5.16183,15.525
5.19212,16.3751
5.44619,17.5022
5.33669,15.9182
5.36902,15.7793
5.36222,15.9064
5.30611,15.2432
5.78051,16.0825
